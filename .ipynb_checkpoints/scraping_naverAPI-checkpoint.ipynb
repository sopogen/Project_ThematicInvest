{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 네이버API 사용 크롤링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import sys\n",
    "import urllib.request\n",
    "import urllib.parse\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-314a55e56950>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-1-314a55e56950>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    curl \"https://openapi.naver.com/v1/papago/n2mt\" \\\u001b[0m\n\u001b[1;37m                                                  ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "curl \"https://openapi.naver.com/v1/papago/n2mt\" \\\n",
    "-H \"Content-Type: application/x-www-form-urlencoded; charset=UTF-8\" \\\n",
    "-H \"X-Naver-Client-Id: vsdXXZ9ntwAeFeejf4qC\" \\\n",
    "-H \"X-Naver-Client-Secret: zHa2LO_TlI\" \\\n",
    "-d \"source=ko&target=en&text=만나서 반갑습니다.\" -v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_id = \"c5S6PYNFitegnG1bJzw5\"\n",
    "client_secret = \"auD1h5XeHn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 네이버 검색 API예제는 블로그를 비롯 전문자료까지 호출방법이 동일하므로 blog검색만 대표로 예제를 올렸습니다.\n",
    "# 네이버 검색 Open API 예제 - 블로그 검색\n",
    "\n",
    "encText = urllib.parse.quote(\"검색할 단어\")\n",
    "url = \"https://openapi.naver.com/v1/search/blog?query=\" + encText # json 결과\n",
    "# url = \"https://openapi.naver.com/v1/search/blog.xml?query=\" + encText # xml 결과\n",
    "request = urllib.request.Request(url)\n",
    "request.add_header(\"X-Naver-Client-Id\",client_id)\n",
    "request.add_header(\"X-Naver-Client-Secret\",client_secret)\n",
    "response = urllib.request.urlopen(request)\n",
    "rescode = response.getcode()\n",
    "if(rescode==200):\n",
    "    response_body = response.read()\n",
    "    print(response_body.decode('utf-8'))\n",
    "else:\n",
    "    print(\"Error Code:\" + rescode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dictionary 형태로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_text = eval(response_body)\n",
    "json_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(json_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_text['display']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_text['items'][0]['description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_text['items'][0]['link']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json_text['items'][0]['link'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pandas 데이터프레임 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df = pd.DataFrame(json_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df['items'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(news_df['items'][0]['link'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df['items'][0]['description']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 네이버API - 뉴스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "\"lastBuildDate\": \"Tue, 09 Jun 2020 19:11:22 +0900\",\n",
      "\"total\": 128768,\n",
      "\"start\": 1,\n",
      "\"display\": 10,\n",
      "\"items\": [\n",
      "{\n",
      "\"title\": \"두나무 증권플러스 비상장, 5월 인기 키워드 삼각편대 '게임-핀테크-방역'\",\n",
      "\"originallink\": \"http://www.cbci.co.kr/news/articleView.html?idxno=407280\",\n",
      "\"link\": \"http://www.cbci.co.kr/news/articleView.html?idxno=407280\",\n",
      "\"description\": \"3~4월에는 코로나19로 인한 방역 관련 <b>테마주</b>가 상위권을 독식했다면 5월은 게임과 핀테크가 강세를 보여... 게임 <b>테마주</b>는 카카오게임즈 외에도 다수가 상위권에 올랐다. 지난 17일 정통 FPS 게임 레드닷(RED DOT)을 론칭한... \",\n",
      "\"pubDate\": \"Tue, 09 Jun 2020 18:52:00 +0900\"\n",
      "\n",
      "},\n",
      "{\n",
      "\"title\": \"[시황] 바이오인식(생체인식) <b>테마주</b> 6월 9일 장마감 시황…젬백스링크·슈프...\",\n",
      "\"originallink\": \"http://www.topstarnews.net/news/articleView.html?idxno=801762\",\n",
      "\"link\": \"http://www.topstarnews.net/news/articleView.html?idxno=801762\",\n",
      "\"description\": \"바이오인식(생체인식) <b>테마주</b>의 6월 9일 장마감 시황은 다음과 같다. 젬백스링크의 주가는 1,615원으로 29.72% 상한가로 마감했다. 젬백스링크의 거래량은 77,340,668주가 거래됐고, 전일거래량은 3,350,277주가... \",\n",
      "\"pubDate\": \"Tue, 09 Jun 2020 16:55:00 +0900\"\n",
      "\n",
      "},\n",
      "{\n",
      "\"title\": \"[시황] 면역항암제 <b>테마주</b> 6월 9일 장마감 시황…녹십자랩셀·티움바이오·크...\",\n",
      "\"originallink\": \"http://www.topstarnews.net/news/articleView.html?idxno=801757\",\n",
      "\"link\": \"http://www.topstarnews.net/news/articleView.html?idxno=801757\",\n",
      "\"description\": \"면역항암제 <b>테마주</b>의 6월 9일 장마감 시황은 다음과 같다. 녹십자랩셀의 주가는 58,100원으로 11.73% 상승하고 마감했다. 녹십자랩셀의 거래량은 2,607,091주가 거래됐고, 전일거래량은 529,239주가 거래됐다.... \",\n",
      "\"pubDate\": \"Tue, 09 Jun 2020 16:51:00 +0900\"\n",
      "\n",
      "},\n",
      "{\n",
      "\"title\": \"'방탄소년단 <b>테마주</b>' 대부분 하락, 엔터테인먼트3사는 SM만 강보합\",\n",
      "\"originallink\": \"http://www.businesspost.co.kr/BP?command=article_view&num=181986\",\n",
      "\"link\": \"http://www.businesspost.co.kr/BP?command=article_view&num=181986\",\n",
      "\"description\": \"'방탄소년단 <b>테마주</b>'로 묶이는 회사 주가가 대부분 내렸다. 9일 경남제약 주가는 전날보다 4.66%(460원) 떨어진 9410원에 거래를 마쳤다. 방탄소년단은 경남제약의 '레모나' 홍보모델로 활동한다. 손오공 주가는 3.04... \",\n",
      "\"pubDate\": \"Tue, 09 Jun 2020 16:40:00 +0900\"\n",
      "\n",
      "},\n",
      "{\n",
      "\"title\": \"[시황] 자전거 <b>테마주</b> 6월 9일 장마감 시황…빅텍·알톤스포츠·삼천리자전거...\",\n",
      "\"originallink\": \"http://www.topstarnews.net/news/articleView.html?idxno=801740\",\n",
      "\"link\": \"http://www.topstarnews.net/news/articleView.html?idxno=801740\",\n",
      "\"description\": \"자전거 <b>테마주</b>의 6월 9일 장마감 시황은 다음과 같다. 빅텍의 주가는 5,120원으로 18.93% 상승하고 마감했다. 빅텍의 거래량은 52,737,659주가 거래됐고, 전일거래량은 34,234,580주가 거래됐다. 빅텍의 시가총액은... \",\n",
      "\"pubDate\": \"Tue, 09 Jun 2020 16:39:00 +0900\"\n",
      "\n",
      "},\n",
      "{\n",
      "\"title\": \"코스피, 8거래일째 상승 이어져…기관·외인은 ‘팔자’\",\n",
      "\"originallink\": \"http://www.joseilbo.com/news/news_read.php?uid=399794&class=53&grp=\",\n",
      "\"link\": \"https://news.naver.com/main/read.nhn?mode=LSD&mid=sec&sid1=101&oid=123&aid=0002225140\",\n",
      "\"description\": \"대체로 코로나19 치료제관련 <b>테마주</b>들을 중심으로 크게 올랐다. 신풍제약과 제일약품은 상한가까지 치솟았다. 부광약품(+24.10%), 종근당(+10.78%), 대웅제약(+10.00%)은 10% 이상 급등했다. 반면 은행과 증권 업종은... \",\n",
      "\"pubDate\": \"Tue, 09 Jun 2020 16:18:00 +0900\"\n",
      "\n",
      "},\n",
      "{\n",
      "\"title\": \"[시황] SNS(소셜네트워크서비스) <b>테마주</b> 6월 9일 장마감 시황…젬백스링크·인...\",\n",
      "\"originallink\": \"http://www.topstarnews.net/news/articleView.html?idxno=801698\",\n",
      "\"link\": \"http://www.topstarnews.net/news/articleView.html?idxno=801698\",\n",
      "\"description\": \"SNS(소셜네트워크서비스) <b>테마주</b>의 6월 9일 장마감 시황은 다음과 같다. 젬백스링크의 주가는 1,615원으로 29.72% 상한가로 마감했다. 젬백스링크의 거래량은 77,337,630주가 거래됐고, 전일거래량은 3,350... \",\n",
      "\"pubDate\": \"Tue, 09 Jun 2020 16:01:00 +0900\"\n",
      "\n",
      "},\n",
      "{\n",
      "\"title\": \"&quot;대통령 후보와 친인척&quot; <b>테마주</b> 유포자에 벌금형\",\n",
      "\"originallink\": \"http://www.honam.co.kr/detail/c3QycN/605273\",\n",
      "\"link\": \"http://www.honam.co.kr/detail/c3QycN/605273\",\n",
      "\"description\": \"2017년 제19대 대통령선거를 앞두고 이른바 정치인 <b>테마주</b> 풍문을 유포한 60대에게 벌금형이 선고됐다. 다만 이익금은 추징되지 않았다. 9일 광주지법 형사7단독(이호산 부장판사)는 자본시장과 금융투자업에 관한 법률... \",\n",
      "\"pubDate\": \"Tue, 09 Jun 2020 15:52:00 +0900\"\n",
      "\n",
      "},\n",
      "{\n",
      "\"title\": \"'코로나19 치료제' 국내 13개 임상 진행중……치료제 12개·백신 1개 '관련주...\",\n",
      "\"originallink\": \"http://www.topstarnews.net/news/articleView.html?idxno=801672\",\n",
      "\"link\": \"http://www.topstarnews.net/news/articleView.html?idxno=801672\",\n",
      "\"description\": \"코로나19 치료제의 활발한 임상시험으로 인해 관련 <b>테마주</b>도 급등세를 이어가고 있다. 아래는 코로나19(진단·치료제·백신 개발) 등 <b>테마주</b> 장마감 시황이다. 제일약품의 현재가는 55,000원으로 29.87... \",\n",
      "\"pubDate\": \"Tue, 09 Jun 2020 15:37:00 +0900\"\n",
      "\n",
      "},\n",
      "{\n",
      "\"title\": \"정치인 <b>테마주</b> 찌라시 유포 60대 벌금형\",\n",
      "\"originallink\": \"https://www.nocutnews.co.kr/news/5358149\",\n",
      "\"link\": \"https://news.naver.com/main/read.nhn?mode=LSD&mid=sec&sid1=102&oid=079&aid=0003369907\",\n",
      "\"description\": \"특정 기업이 유력 정치인과 관계가 있다는 이야기를 유포해 주가 차익을 얻으려 한 60대에게 법원이 벌금형을 선고했다. 광주지방법원 형사 7 단독 이호산 부장판사는 자본시장과 금융투자업에 관한 법률 위반 혐의로... \",\n",
      "\"pubDate\": \"Tue, 09 Jun 2020 15:32:00 +0900\"\n",
      "\n",
      "}\n",
      "]\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#네이버 검색 Open API 예제 - 뉴스 검색\n",
    "\n",
    "encText = urllib.parse.quote(\"테마주\")\n",
    "url = \"https://openapi.naver.com/v1/search/news?query=\" + encText # json 결과\n",
    "# url = \"https://openapi.naver.com/v1/search/blog.xml?query=\" + encText # xml 결과\n",
    "request = urllib.request.Request(url)\n",
    "request.add_header(\"X-Naver-Client-Id\",client_id)\n",
    "request.add_header(\"X-Naver-Client-Secret\",client_secret)\n",
    "response = urllib.request.urlopen(request)\n",
    "rescode = response.getcode()\n",
    "if(rescode==200):\n",
    "    response_body = response.read()\n",
    "    print(response_body.decode('utf-8'))\n",
    "else:\n",
    "    print(\"Error Code:\" + rescode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(response_body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_enter = 'https://entertain.naver.com/read?oid=417&aid=0000458809'\n",
    "print(url_enter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "html = requests.get(url_enter)\n",
    "print(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup1 = BeautifulSoup(html.text, 'lxml')\n",
    "print(soup1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# title 정보에 접근\n",
    "soup1.title.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "\n",
    "html = urlopen(url_enter)\n",
    "print(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "soup2 = BeautifulSoup(html, 'lxml')\n",
    "print(soup2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# title 정보에 접근\n",
    "soup2.title.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soupx = soup2\n",
    "\n",
    "media = soupx.find('meta',attrs={'name':'twitter:creator'}).get('content').strip() # media\n",
    "title = soupx.find('meta',attrs={'property':'og:title'}).get('content').strip() # title\n",
    "url = soupx.find('meta', attrs={'property':'og:url'}).get('content') # URL\n",
    "section = soupx.find('meta', attrs={'name':'twitter:site'}).get('content') # Section\n",
    "gdid = url.split('aid=')[1].split(\"&\")[0]\n",
    "body  = soupx.find('div', attrs={'class':'article_body'}).text.strip() # body\n",
    "\n",
    "try: category = soupx.find('meta', attrs={'property':'me2:category2'}).get('content') # category\n",
    "except: category = ''\n",
    "\n",
    "news_info={'0gdid':gdid, '1title':title, '2url':url, '3section':section, '4category':category, '5body':body}\n",
    "print(news_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_info['5body']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 반복 수행을 위한 함수 작성 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_article(url):\n",
    "    html = urlopen(url)\n",
    "    time.sleep(1) # 반드시 time.sleep() 시간차 함수를 넣기 바람\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    #print(url)\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '네이버'뉴스에 게재된 '연예'뉴스 포맷에만 적용 가능\n",
    "def extract_information_enternews(soupx):\n",
    "    media = soupx.find('meta',attrs={'name':'twitter:creator'}).get('content').strip() # media\n",
    "    title = soupx.find('meta',attrs={'property':'og:title'}).get('content').strip() # title\n",
    "    url = soupx.find('meta', attrs={'property':'og:url'}).get('content') # URL\n",
    "    section = soupx.find('meta', attrs={'name':'twitter:site'}).get('content') # Section\n",
    "    gdid = url.split('aid=')[1].split(\"&\")[0]\n",
    "    body  = soupx.find('div', attrs={'class':'article_body'}).text.strip() # body\n",
    "\n",
    "    try: category = soupx.find('meta', attrs={'property':'me2:category2'}).get('content') # category\n",
    "    except: category = ''\n",
    "            \n",
    "    news_info={'0gdid':gdid, '1title':title, '2url':url, '3section':section, '4category':category, '5body':body}\n",
    "\n",
    "    return news_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 함수를 사용해 웹페이지 소스에서 정보 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_enter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soupx_enter = soup2\n",
    "extract_information_enternews(soupx_enter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 네이버 뉴스가 아닌 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_not_naver = json_text['items'][2]['link']\n",
    "print(json_text['items'][2])\n",
    "print(url_not_naver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soupx_not_naver = get_article(url_not_naver)\n",
    "extract_information_enternews(soupx_not_naver) # 에러 발생"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 네이버 뉴스 중, '연예' 뉴스가 아닌 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_social='https://news.naver.com/main/read.nhn?mode=LSD&mid=sec&oid=025&aid=0002944990&sid1=001'\n",
    "print(url_social)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soupx_social = get_article(url_social)\n",
    "extract_information_enternews(soupx_social)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 반복문을 이용한 정보 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    url_enter = json_text['items'][i]['link']\n",
    "    print(url_enter) # 네이버 연예뉴스가 아닐 경우, 에러 및 중단 발생\n",
    "    soupx_enter = get_article(url_enter)\n",
    "    extract_information_enternews(soupx_enter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try-except 구문 활용\n",
    "for i in range(10):\n",
    "    url_enter = json_text['items'][i]['link']\n",
    "    print(url_enter)\n",
    "    try: # 에러가 발생하지 않을 경우, 다음의 명령문 실행\n",
    "        soupx_enter = get_article(url_enter)\n",
    "        print(extract_information_enternews(soupx_enter)) # 추출한 정보 출력\n",
    "    except:\n",
    "        pass  # 에러가 발생할 경우, (중단하지 않고) 다음 i 차례로 넘어감"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 예시) 1년치 뉴스를 수집하는 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_str_day1 = [x for x in ['01.01','01.16','02.01']]\n",
    "url_str_day2 = [x for x in ['01.15','01.31','02.15']]\n",
    "#url_str_day1 = [x for x in ['01.01','01.16','02.01','02.16','03.01','03.16','04.01','04.16','05.01','05.16','06.01','06.16',\n",
    "#                            '07.01','07.16','08.01','08.16','09.01','09.16','10.01','10.16','11.01','11.16','12.01','12.16']]\n",
    "#url_str_day2 = [x for x in ['01.15','01.31','02.15','02.28','03.15','03.31','04.15','04.30','05.15','05.31','06.15','06.30',\n",
    "#                            '07.15','07.31','08.15','08.31','09.15','09.30','10.15','10.31','11.15','11.30','12.15','12.31']]\n",
    "​\n",
    "naver_search_url = []\n",
    "search_result_count_sum = 0\n",
    "for k in range(len(url_str_day1)):\n",
    "    url_search_str0 = 'https://search.naver.com/search.naver?&where=news&query=%22%5B%EB%8B%A8%EB%8F%85%5D%22&sm=tab_pge&sort=2&photo=0&field=1&reporter_article=&pd=3&ds=2018.'\n",
    "    url_search_str_add1 = url_str_day1[k] #'01.01'\n",
    "    url_search_str_add2 = '&de=2018.' + url_str_day2[k] #'12.31'\n",
    "    url_search_str_add3 = '&docid=&nso=so:da,p:from2018' + url_str_day1[k].replace('.','') #'0101'\n",
    "    url_search_str_add4 = 'to2018' + url_str_day2[k].replace('.','') #'1231'\n",
    "    url_search_str_add5 = ',a:t&mynews=101&start='\n",
    "    url_search_str0 = url_search_str0+url_search_str_add1+url_search_str_add2+url_search_str_add3+url_search_str_add4+url_search_str_add5\n",
    "    url_search_firstpage = url_search_str0 + '1&refresh_start=0'\n",
    "    naver_search_url.append(url_search_firstpage)\n",
    "    soup_naver_search_firstpage = get_article(url_search_firstpage)\n",
    "    search_result_pages = soup_naver_search_firstpage.find('div', attrs={'class':'title_desc all_my'}).text.split()[2]\n",
    "    search_result_count = int(search_result_pages.replace('건','').replace(',',''))\n",
    "    search_result_count_sum += search_result_count\n",
    "    search_result_count_pages = int(search_result_count/10)\n",
    "    print(url_search_firstpage, search_result_pages, search_result_count_pages)\n",
    "    #for j in range(0, search_result_count_pages):\n",
    "    for j in range(0, 1):\n",
    "        jx = j*10 + 11\n",
    "        url_search_pages = url_search_str0 + str(jx) + '&refresh_start=0'\n",
    "        naver_search_url.append(url_search_pages)\n",
    "        #print(url_search_pages)\n",
    "print(search_result_count_sum)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
