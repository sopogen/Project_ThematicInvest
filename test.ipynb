{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38264bit38446791c39c46089dad72dbad282c86",
   "display_name": "Python 3.8.2 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "using cached model\n"
    }
   ],
   "source": [
    "# Set word2vec parameters\n",
    "tok_path = get_tokenizer()\n",
    "sp = SentencepieceTokenizer(tok_path)\n",
    "v_dimension = 300\n",
    "v_window = 8\n",
    "model = Word2Vec.load('/modeling/word2vec.model')\n",
    "\n",
    "def vectorize_without_normal(news):\n",
    "    # Remove letters which are not Hangul\n",
    "    hangul = re.compile(\"[^ㄱ-ㅎㅏ-ㅣ가-힣]+\")\n",
    "    news_words = hangul.sub(' ', news)\n",
    "    # Tokenization with KoBERT tokenizer\n",
    "    token = sp(news)\n",
    "    final_tokens = token\n",
    "    # Vectorization with word2vec\n",
    "    init_v = np.array([0.0]*v_dimension)\n",
    "    for word in final_tokens:\n",
    "        word_vectors = model.wv\n",
    "        if word in word_vectors.vocab:\n",
    "            v = model.wv[word]\n",
    "            init_v = init_v + v\n",
    "    return init_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "from scipy.spatial import distance\n",
    "from gluonnlp.data import SentencepieceTokenizer\n",
    "from kobert.utils import get_tokenizer\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from urllib.request import urlopen\n",
    "from urllib.parse import quote\n",
    "import requests\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import re\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_news = \"미국의 최대 새해맞이 행사죠, '뉴 이어스 로킹 이브'에 방탄소년단이 출연해 월드 스타로서의 면모를 과시했습니다. 지난해 빌보드 순위와 월드 투어에서 괄목할 만한 성장을 거둔 방탄소년단, 올해도 한류를 이끌 것으로 기대되고 있습니다. 김혜은 기자입니다. 방탄소년단, BTS는 미국 뉴욕의 심장인 타임스퀘어에서 새해를 맞았습니다. 미국의 최대 새해맞이 행사인 '뉴 이어스 로킹 이브'에 참가한 것입니다. 포스트 말론, 샘 헌트 등 세계적인 가수들과 어깨를 나란히 하며 미국 안방에 스며들었습니다. [리안나 제이콥슨 / BTS 팬 : BTS가 사랑받고 있다는 것, 그들이 놀랍고 재능 있고 매 순간 가치 있다는 것을 알려줘야 합니다.] BTS는 지난해 '빌보드 200' 1위와 아메리칸 뮤직 어워즈 3관왕 등 괄목할 기록을 낳았습니다. 한국 가수 최초로 전 세계 스타디움 투어도 성공적으로 마무리했습니다. 투어의 대미를 장식한 서울 공연에서만 사흘 동안 무려 1조 원에 육박하는 경제 효과를 낳은 것으로 집계됐습니다. 공연으로 18만 명 넘는 외국인이 우리나라를 방문했는데, 평창동계올림픽 당시 외국인 방문객의 67%에 해당하는 수치입니다. BTS의 올해 행보에 더욱 기대가 쏠리는 대목입니다. 지난달 공개한 티저 사진으로 올 초 예정된 새 앨범과 투어에 대한 기대감이 올라갔습니다. [지민 / 방탄소년단 멤버 (지난달 MAMA 시상식) : 여러분들이 기대하시는 것보다 훨씬 더 좋은 앨범으로 저희가 여러분들에게 나타날 수 있을 것 같아요.] BTS 이후 '빌보드200' 1위를 차지한 슈퍼엠, 미국 프로그램에 자주 등장하는 몬스타엑스와 NCT 127 등 K팝의 지형은 갈수록 확대되고 있습니다. [김헌식 / 대중문화평론가 : 음악의 유통구조 자체가 유튜브를 포함한 SNS를 중심으로 확산하고 있기 때문에 여기에서 계속 추이를 따라가는 수준이라면 10년 이상까지도 가능할 수 있다는 거죠.] 새로운 10년이 시작되는 2020년, BTS가 미국 심장부인 뉴욕에서 새해를 시작한 것도, 한류의 새로운 10년에 대한 상징으로도 해석되고 있습니다.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-729cefdea3d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorize_without_normal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_news\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mvec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-491a6550b76a>\u001b[0m in \u001b[0;36mvectorize_without_normal\u001b[0;34m(news)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0minit_v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mv_dimension\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfinal_tokens\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mword_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword_vectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "vec = vectorize_without_normal(test_news)\n",
    "vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}