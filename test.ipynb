{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38264bit38446791c39c46089dad72dbad282c86",
   "display_name": "Python 3.8.2 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "from scipy.spatial import distance\n",
    "from gluonnlp.data import SentencepieceTokenizer\n",
    "from kobert.utils import get_tokenizer\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from urllib.request import urlopen\n",
    "from urllib.parse import quote\n",
    "import requests\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import re\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "using cached model\n"
    }
   ],
   "source": [
    "# Set word2vec parameters\n",
    "tok_path = get_tokenizer()\n",
    "sp = SentencepieceTokenizer(tok_path)\n",
    "v_dimension = 300\n",
    "v_window = 8\n",
    "model = Word2Vec.load('modeling/word2vec.model')\n",
    "\n",
    "def vectorize_without_normal(news):\n",
    "    # Remove letters which are not Hangul\n",
    "    hangul = re.compile(\"[^ㄱ-ㅎㅏ-ㅣ가-힣]+\")\n",
    "    news_words = hangul.sub(' ', news)  \n",
    "    # Tokenization with KoBERT tokenizer\n",
    "    token = sp(news)\n",
    "    final_tokens = token\n",
    "    # Vectorization with word2vec\n",
    "    init_v = np.array([0.0]*v_dimension)\n",
    "    for word in final_tokens:\n",
    "        word_vectors = model.wv\n",
    "        if word in word_vectors.vocab:\n",
    "            v = model.wv[word]\n",
    "            init_v = init_v + v\n",
    "    return init_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_news = \"[서울경제] 유럽연합(EU) 집행위원회는 2일(현지시간) 현대차 그룹이 유럽의 전기차 충전 인프라 업체인 ‘아이오니티’(IONITY)의 지분 인수를 승인했다. EU 집행위는 보도자료에서 현대차가 아이오니티에 대해 기존의 다임러, BMW, 포르쉐, 포드와 공동지배권을 갖는 것을 허가했다고 밝혔다. EU는 현대차의 지분 인수가 시장에 미치는 영향이 제한적이라고 승인 이유를 설명했다. EU는 현대차에 대해 “전 세계적으로 자동차의 제조에 적극적이고 자회사인 현대캐피탈을 통해 금융 서비스를 제공하고 있다”고 평가했다. 앞서 현대차는 지난해 9월 아이오니티의 지분을 다임러, BMW, 포르셰, 포드와 동일하게 20% 인수하기로 했다고 발표한 바 있다. 아이오니티 지분 인수는 현대차가 유럽 시장에서 자체 개발하는 고전압 전기차 판매 확대를 위한 것이다. 아이오니티는 기존 급속 충전기보다 충전 속도가 최대 7배 빠른 350kW급 초고속 충전 인프라 구축에 집중하고 있다. 아이오니티가 제공하는 350kW급 초고속 충전기는 3분 충전만으로 100㎞ 이상 주행이 가능하다. 아이오니티는 디지털 결제 방식과 유럽 전기차 충전 표준을 적용해서 전기차 제조사에 구애받지 않는 광범위한 호환성을 갖췄다. /서종갑기자 gap@sedaily.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "' 서울경제 유럽연합 집행위원회는 일 현지시간 현대차 그룹이 유럽의 전기차 충전 인프라 업체인 아이오니티 의 지분 인수를 승인했다 집행위는 보도자료에서 현대차가 아이오니티에 대해 기존의 다임러 포르쉐 포드와 공동지배권을 갖는 것을 허가했다고 밝혔다 는 현대차의 지분 인수가 시장에 미치는 영향이 제한적이라고 승인 이유를 설명했다 는 현대차에 대해 전 세계적으로 자동차의 제조에 적극적이고 자회사인 현대캐피탈을 통해 금융 서비스를 제공하고 있다 고 평가했다 앞서 현대차는 지난해 월 아이오니티의 지분을 다임러 포르셰 포드와 동일하게 인수하기로 했다고 발표한 바 있다 아이오니티 지분 인수는 현대차가 유럽 시장에서 자체 개발하는 고전압 전기차 판매 확대를 위한 것이다 아이오니티는 기존 급속 충전기보다 충전 속도가 최대 배 빠른 급 초고속 충전 인프라 구축에 집중하고 있다 아이오니티가 제공하는 급 초고속 충전기는 분 충전만으로 이상 주행이 가능하다 아이오니티는 디지털 결제 방식과 유럽 전기차 충전 표준을 적용해서 전기차 제조사에 구애받지 않는 광범위한 호환성을 갖췄다 서종갑기자 '"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "hangul = re.compile(\"[^ㄱ-ㅎㅏ-ㅣ가-힣]+\")\n",
    "news_words = hangul.sub(' ', test_news)\n",
    "news_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = MeCab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<module 'MeCab' from '/opt/anaconda3/envs/projects/lib/python3.8/site-packages/MeCab.py'>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}